<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>
<title>Acoustic Keylogging via Smartphone devices - Corpus.md</title><style type='text/css'>html {overflow-x: initial !important;}:root { --bg-color: #ffffff; --text-color: #333333; --code-block-bg-color: inherit; }
html { font-size: 14px; background-color: var(--bg-color); color: var(--text-color); font-family: "Helvetica Neue", Helvetica, Arial, sans-serif; }
body { margin: 0px; padding: 0px; height: auto; bottom: 0px; top: 0px; left: 0px; right: 0px; font-size: 1rem; line-height: 1.42857; overflow-x: hidden; background: inherit; }
a:active, a:hover { outline: 0px; }
.in-text-selection, ::selection { background: rgb(181, 214, 252); text-shadow: none; }
#write { margin: 0px auto; height: auto; width: inherit; word-break: normal; word-wrap: break-word; position: relative; padding-bottom: 70px; white-space: pre-wrap; overflow-x: visible; }
.for-image #write { padding-left: 8px; padding-right: 8px; }
body.typora-export { padding-left: 30px; padding-right: 30px; }
@media screen and (max-width: 500px) {
  body.typora-export { padding-left: 0px; padding-right: 0px; }
  .CodeMirror-sizer { margin-left: 0px !important; }
  .CodeMirror-gutters { display: none !important; }
}
.typora-export #write { margin: 0px auto; }
#write > p:first-child, #write > ul:first-child, #write > ol:first-child, #write > pre:first-child, #write > blockquote:first-child, #write > div:first-child, #write > table:first-child { margin-top: 30px; }
#write li > table:first-child { margin-top: -20px; }
img { max-width: 100%; vertical-align: middle; }
input, button, select, textarea { color: inherit; font-style: inherit; font-variant: inherit; font-weight: inherit; font-stretch: inherit; font-size: inherit; line-height: inherit; font-family: inherit; }
input[type="checkbox"], input[type="radio"] { line-height: normal; padding: 0px; }
::before, ::after, * { box-sizing: border-box; }
#write p, #write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write div, #write pre { width: inherit; }
#write p, #write h1, #write h2, #write h3, #write h4, #write h5, #write h6 { position: relative; }
h1 { font-size: 2rem; }
h2 { font-size: 1.8rem; }
h3 { font-size: 1.6rem; }
h4 { font-size: 1.4rem; }
h5 { font-size: 1.2rem; }
h6 { font-size: 1rem; }
p { -webkit-margin-before: 1rem; -webkit-margin-after: 1rem; -webkit-margin-start: 0px; -webkit-margin-end: 0px; }
.typora-export p { white-space: normal; }
.mathjax-block { margin-top: 0px; margin-bottom: 0px; -webkit-margin-before: 0rem; -webkit-margin-after: 0rem; }
.hidden { display: none; }
.md-blockmeta { color: rgb(204, 204, 204); font-weight: bold; font-style: italic; }
a { cursor: pointer; }
sup.md-footnote { padding: 2px 4px; background-color: rgba(238, 238, 238, 0.7); color: rgb(85, 85, 85); border-radius: 4px; }
#write input[type="checkbox"] { cursor: pointer; width: inherit; height: inherit; margin: 4px 0px 0px; }
tr { break-inside: avoid; break-after: auto; }
thead { display: table-header-group; }
table { border-collapse: collapse; border-spacing: 0px; width: 100%; overflow: auto; break-inside: auto; text-align: left; }
table.md-table td { min-width: 80px; }
.CodeMirror-gutters { border-right: 0px; background-color: inherit; }
.CodeMirror { text-align: left; }
.CodeMirror-placeholder { opacity: 0.3; }
.CodeMirror pre { padding: 0px 4px; }
.CodeMirror-lines { padding: 0px; }
div.hr:focus { cursor: none; }
pre { white-space: pre-wrap; }
.CodeMirror-gutters { margin-right: 4px; }
.md-fences { font-size: 0.9rem; display: block; break-inside: avoid; text-align: left; overflow: visible; white-space: pre; background: var(--code-block-bg-color); position: relative !important; }
.md-diagram-panel { width: 100%; margin-top: 10px; text-align: center; padding-top: 0px; padding-bottom: 8px; overflow-x: auto; }
.md-fences .CodeMirror.CodeMirror-wrap { top: -1.6em; margin-bottom: -1.6em; }
.md-fences.mock-cm { white-space: pre-wrap; }
.show-fences-line-number .md-fences { padding-left: 0px; }
.show-fences-line-number .md-fences.mock-cm { padding-left: 40px; }
.footnotes { opacity: 0.8; font-size: 0.9rem; padding-top: 1em; padding-bottom: 1em; }
.footnotes + .footnotes { margin-top: -1em; }
.md-reset { margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: top; background: transparent; text-decoration: none; text-shadow: none; float: none; position: static; width: auto; height: auto; white-space: nowrap; cursor: inherit; -webkit-tap-highlight-color: transparent; line-height: normal; font-weight: normal; text-align: left; box-sizing: content-box; direction: ltr; }
li div { padding-top: 0px; }
blockquote { margin: 1rem 0px; }
li p, li .mathjax-block { margin: 0.5rem 0px; }
li { margin: 0px; position: relative; }
blockquote > :last-child { margin-bottom: 0px; }
blockquote > :first-child { margin-top: 0px; }
.footnotes-area { color: rgb(136, 136, 136); margin-top: 0.714rem; padding-bottom: 0.143rem; }
@media print {
  html, body { border: 1px solid transparent; height: 99%; break-after: avoid; break-before: avoid; }
  .typora-export * { -webkit-print-color-adjust: exact; }
  h1, h2, h3, h4, h5, h6 { break-after: avoid-page; orphans: 2; }
  p { orphans: 4; }
  html.blink-to-pdf { font-size: 13px; }
  .typora-export #write { padding-left: 1cm; padding-right: 1cm; padding-bottom: 0px; break-after: avoid; }
  .typora-export #write::after { height: 0px; }
  @page { margin: 20mm 0mm; }
}
.footnote-line { margin-top: 0.714em; font-size: 0.7em; }
a img, img a { cursor: pointer; }
pre.md-meta-block { font-size: 0.8rem; min-height: 2.86rem; white-space: pre-wrap; background: rgb(204, 204, 204); display: block; overflow-x: hidden; }
p .md-image:only-child { display: inline-block; width: 100%; text-align: center; }
#write .MathJax_Display { margin: 0.8em 0px 0px; }
.mathjax-block { white-space: pre; overflow: hidden; width: 100%; }
p + .mathjax-block { margin-top: -1.143rem; }
.mathjax-block:not(:empty)::after { display: none; }
[contenteditable="true"]:active, [contenteditable="true"]:focus { outline: none; box-shadow: none; }
.task-list { list-style-type: none; }
.task-list-item { position: relative; padding-left: 1em; }
.task-list-item input { position: absolute; top: 0px; left: 0px; }
.math { font-size: 1rem; }
.md-toc { min-height: 3.58rem; position: relative; font-size: 0.9rem; border-radius: 10px; }
.md-toc-content { position: relative; margin-left: 0px; }
.md-toc::after, .md-toc-content::after { display: none; }
.md-toc-item { display: block; color: rgb(65, 131, 196); text-decoration: none; }
.md-toc-inner:hover { }
.md-toc-inner { display: inline-block; cursor: pointer; }
.md-toc-h1 .md-toc-inner { margin-left: 0px; font-weight: bold; }
.md-toc-h2 .md-toc-inner { margin-left: 2em; }
.md-toc-h3 .md-toc-inner { margin-left: 4em; }
.md-toc-h4 .md-toc-inner { margin-left: 6em; }
.md-toc-h5 .md-toc-inner { margin-left: 8em; }
.md-toc-h6 .md-toc-inner { margin-left: 10em; }
@media screen and (max-width: 48em) {
  .md-toc-h3 .md-toc-inner { margin-left: 3.5em; }
  .md-toc-h4 .md-toc-inner { margin-left: 5em; }
  .md-toc-h5 .md-toc-inner { margin-left: 6.5em; }
  .md-toc-h6 .md-toc-inner { margin-left: 8em; }
}
a.md-toc-inner { font-size: inherit; font-style: inherit; font-weight: inherit; line-height: inherit; }
.footnote-line a:not(.reversefootnote) { color: inherit; }
.md-attr { display: none; }
.md-fn-count::after { content: "."; }
.md-tag { opacity: 0.5; }
.md-comment { color: rgb(162, 127, 3); opacity: 0.8; font-family: monospace; }
code { text-align: left; }
h1 .md-tag, h2 .md-tag, h3 .md-tag, h4 .md-tag, h5 .md-tag, h6 .md-tag { font-weight: initial; opacity: 0.35; }
a.md-print-anchor { border-width: initial !important; border-style: none !important; border-color: initial !important; display: inline-block !important; position: absolute !important; width: 1px !important; right: 0px !important; outline: none !important; background: transparent !important; text-decoration: initial !important; text-shadow: initial !important; }
.md-inline-math .MathJax_SVG .noError { display: none !important; }
.mathjax-block .MathJax_SVG_Display { text-align: center; margin: 1em 0em; position: relative; text-indent: 0px; max-width: none; max-height: none; min-height: 0px; min-width: 100%; width: auto; display: block !important; }
.MathJax_SVG_Display, .md-inline-math .MathJax_SVG_Display { width: auto; margin: inherit; display: inline-block !important; }
.MathJax_SVG .MJX-monospace { font-family: monospace; }
.MathJax_SVG .MJX-sans-serif { font-family: sans-serif; }
.MathJax_SVG { display: inline; font-style: normal; font-weight: normal; line-height: normal; zoom: 90%; text-indent: 0px; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; padding: 0px; margin: 0px; }
.MathJax_SVG * { transition: none; }
.md-diagram-panel > svg { max-width: 100%; }
[lang="flow"] svg, [lang="mermaid"] svg { max-width: 100%; }


:root { --side-bar-bg-color: #fafafa; --control-text-color: #777; }
@font-face { font-family: "Open Sans"; font-style: normal; font-weight: normal; src: local("Open Sans Regular"), url("./github/400.woff") format("woff"); }
@font-face { font-family: "Open Sans"; font-style: italic; font-weight: normal; src: local("Open Sans Italic"), url("./github/400i.woff") format("woff"); }
@font-face { font-family: "Open Sans"; font-style: normal; font-weight: bold; src: local("Open Sans Bold"), url("./github/700.woff") format("woff"); }
@font-face { font-family: "Open Sans"; font-style: italic; font-weight: bold; src: local("Open Sans Bold Italic"), url("./github/700i.woff") format("woff"); }
html { font-size: 16px; }
body { font-family: "Open Sans", "Clear Sans", "Helvetica Neue", Helvetica, Arial, sans-serif; color: rgb(51, 51, 51); line-height: 1.6; }
#write { max-width: 860px; margin: 0px auto; padding: 20px 30px 100px; }
#write > ul:first-child, #write > ol:first-child { margin-top: 30px; }
body > :first-child { margin-top: 0px !important; }
body > :last-child { margin-bottom: 0px !important; }
a { color: rgb(65, 131, 196); }
h1, h2, h3, h4, h5, h6 { position: relative; margin-top: 1rem; margin-bottom: 1rem; font-weight: bold; line-height: 1.4; cursor: text; }
h1:hover a.anchor, h2:hover a.anchor, h3:hover a.anchor, h4:hover a.anchor, h5:hover a.anchor, h6:hover a.anchor { text-decoration: none; }
h1 tt, h1 code { font-size: inherit; }
h2 tt, h2 code { font-size: inherit; }
h3 tt, h3 code { font-size: inherit; }
h4 tt, h4 code { font-size: inherit; }
h5 tt, h5 code { font-size: inherit; }
h6 tt, h6 code { font-size: inherit; }
h1 { padding-bottom: 0.3em; font-size: 2.25em; line-height: 1.2; border-bottom: 1px solid rgb(238, 238, 238); }
h2 { padding-bottom: 0.3em; font-size: 1.75em; line-height: 1.225; border-bottom: 1px solid rgb(238, 238, 238); }
h3 { font-size: 1.5em; line-height: 1.43; }
h4 { font-size: 1.25em; }
h5 { font-size: 1em; }
h6 { font-size: 1em; color: rgb(119, 119, 119); }
p, blockquote, ul, ol, dl, table { margin: 0.8em 0px; }
li > ol, li > ul { margin: 0px; }
hr { height: 4px; padding: 0px; margin: 16px 0px; background-color: rgb(231, 231, 231); border-width: 0px 0px 1px; border-style: none none solid; border-top-color: initial; border-right-color: initial; border-left-color: initial; border-image: initial; overflow: hidden; box-sizing: content-box; border-bottom-color: rgb(221, 221, 221); }
body > h2:first-child { margin-top: 0px; padding-top: 0px; }
body > h1:first-child { margin-top: 0px; padding-top: 0px; }
body > h1:first-child + h2 { margin-top: 0px; padding-top: 0px; }
body > h3:first-child, body > h4:first-child, body > h5:first-child, body > h6:first-child { margin-top: 0px; padding-top: 0px; }
a:first-child h1, a:first-child h2, a:first-child h3, a:first-child h4, a:first-child h5, a:first-child h6 { margin-top: 0px; padding-top: 0px; }
h1 p, h2 p, h3 p, h4 p, h5 p, h6 p { margin-top: 0px; }
li p.first { display: inline-block; }
ul, ol { padding-left: 30px; }
ul:first-child, ol:first-child { margin-top: 0px; }
ul:last-child, ol:last-child { margin-bottom: 0px; }
blockquote { border-left: 4px solid rgb(221, 221, 221); padding: 0px 15px; color: rgb(119, 119, 119); }
blockquote blockquote { padding-right: 0px; }
table { padding: 0px; word-break: initial; }
table tr { border-top: 1px solid rgb(204, 204, 204); margin: 0px; padding: 0px; }
table tr:nth-child(2n) { background-color: rgb(248, 248, 248); }
table tr th { font-weight: bold; border: 1px solid rgb(204, 204, 204); text-align: left; margin: 0px; padding: 6px 13px; }
table tr td { border: 1px solid rgb(204, 204, 204); text-align: left; margin: 0px; padding: 6px 13px; }
table tr th:first-child, table tr td:first-child { margin-top: 0px; }
table tr th:last-child, table tr td:last-child { margin-bottom: 0px; }
.CodeMirror-gutters { border-right: 1px solid rgb(221, 221, 221); }
.md-fences, code, tt { border: 1px solid rgb(221, 221, 221); background-color: rgb(248, 248, 248); border-radius: 3px; font-family: Consolas, "Liberation Mono", Courier, monospace; padding: 2px 4px 0px; font-size: 0.9em; }
.md-fences { margin-bottom: 15px; margin-top: 15px; padding: 8px 1em 6px; }
.task-list { padding-left: 0px; }
.task-list-item { padding-left: 32px; }
.task-list-item input { top: 3px; left: 8px; }
@media screen and (min-width: 914px) {
}
@media print {
  html { font-size: 13px; }
  table, pre { break-inside: avoid; }
  pre { word-wrap: break-word; }
}
.md-fences { background-color: rgb(248, 248, 248); }
#write pre.md-meta-block { padding: 1rem; font-size: 85%; line-height: 1.45; background-color: rgb(247, 247, 247); border: 0px; border-radius: 3px; color: rgb(119, 119, 119); margin-top: 0px !important; }
.mathjax-block > .code-tooltip { bottom: 0.375rem; }
#write > h3.md-focus::before { left: -1.5625rem; top: 0.375rem; }
#write > h4.md-focus::before { left: -1.5625rem; top: 0.285714rem; }
#write > h5.md-focus::before { left: -1.5625rem; top: 0.285714rem; }
#write > h6.md-focus::before { left: -1.5625rem; top: 0.285714rem; }
.md-image > .md-meta { border: 1px solid rgb(221, 221, 221); border-radius: 3px; font-family: Consolas, "Liberation Mono", Courier, monospace; padding: 2px 4px 0px; font-size: 0.9em; color: inherit; }
.md-tag { color: inherit; }
.md-toc { margin-top: 20px; padding-bottom: 20px; }
.sidebar-tabs { border-bottom: none; }
#typora-quick-open { border: 1px solid rgb(221, 221, 221); background-color: rgb(248, 248, 248); }
#typora-quick-open-item { background-color: rgb(250, 250, 250); border-color: rgb(254, 254, 254) rgb(229, 229, 229) rgb(229, 229, 229) rgb(238, 238, 238); border-style: solid; border-width: 1px; }
#md-notification::before { top: 10px; }
.on-focus-mode blockquote { border-left-color: rgba(85, 85, 85, 0.12); }
header, .context-menu, .megamenu-content, footer { font-family: "Segoe UI", Arial, sans-serif; }
.file-node-content:hover .file-node-icon, .file-node-content:hover .file-node-open-state { visibility: visible; }
.mac-seamless-mode #typora-sidebar { background-color: var(--side-bar-bg-color); }






</style>
</head>
<body class='typora-export' >
<div  id='write'  class = 'is-node'><p><div style="position:fixed; top:0; left:0; margin:10px;">
<a href="#contents">Back to Contents</a>
</div></p><h1><a name='header-n174' class='md-header-anchor '></a>Acoustic Keylogging via Smartphone devices - Corpus</h1><h2><a name='header-n1169' class='md-header-anchor '></a>Contents</h2><ol><li><p><strong>Introduction</strong></p><ul><li>Author &amp; date</li><li>Abstract and Aim</li><li>Special Thanks</li></ul></li><li><p><strong>Meetings</strong></p><ul><li>Purpose</li></ul><ul><li>Audio files</li><li>Meeting summaries</li></ul></li><li><p><strong>Previous Research</strong></p><ul><li>Accelerometer Side Channel Attacks</li><li>Cracking Passwords using keyboard acoustics and language modelling</li><li>Keyboard Acoustic Emanations</li><li>Keyboard Acoustic Emanations Revisited</li><li>Electronic emanations of wired and wireless keyboards</li></ul></li><li><p><strong>Hardware</strong></p><ul><li><p>Smartphone Technology</p><ul><li>Microphone</li></ul></li><li><p>The Android Operating System</p><ul><li>Android &#39;Java&#39;</li></ul></li><li><p>Keyboard Hardware</p></li></ul></li><li><p><strong>Testing conditions</strong></p><ul><li><p>Constraints</p><ul><li><p>Keyboard </p><ul><li>Location</li><li>Membrane vs Mechanical </li></ul></li><li><p>Smartphone </p><ul><li>Operating System </li><li>Microphone</li></ul></li><li><p>Lab conditions</p></li></ul></li><li><p>Variables</p><ul><li>Background noise</li><li>Phone model</li><li>Location of phone</li><li>Keyboard </li></ul></li></ul></li><li><p><strong>Testing methodology</strong></p><ul><li><p>Initial testing plans</p></li><li><p>Testing process</p><ul><li>Small subset</li><li>Larger subset</li></ul></li></ul></li><li><p><strong>Feature extraction</strong></p><ul><li><p>Features</p><ul><li>Amplitude</li><li>Frequency</li></ul></li><li><p>Pre-recorded audio extraction</p></li><li><p>Live audio extraction </p></li><li><p>Isolating peaks</p><ul><li>Subsampling</li></ul></li></ul></li><li><p><strong>Feature Analysis</strong></p><ul><li><p>Simple comparison</p></li><li><p>Supervised and unsupervised learning</p><ul><li>Mean approximation </li><li>Kmeans clustering</li></ul></li><li><p></p></li></ul></li><li><p><strong>Development process</strong></p><ul><li><p>Development process ideology</p><ul><li>Iterative design</li><li>Version control</li><li>IDE (Integrated Development Environment)</li></ul></li><li><p>Program functionality</p><ul><li>Learning capabilities</li><li>Data management</li><li>Visualisation</li></ul></li><li><p>Program Steps</p><ul><li><p>Initial Setup</p><ul><li>Launch</li><li>GUI building</li><li>Dataset loading</li><li>Thread establishment</li></ul></li><li><p>Feature Extraction</p></li><li><p>Feature Analysis</p></li><li><p>Supervised/Unsupervised Learning</p><ul><li><p>Mean approximation</p></li><li><p>Kmeans clustering</p><ul><li>1 dimensional</li><li>2 dimensional</li></ul></li></ul></li><li><p>Storing results</p></li></ul></li><li><p>Android API</p><ul><li>API Permissions</li><li>AudioRecord</li><li>Thread management</li><li>XML Design Layouts</li></ul></li><li><p>Storage facilities</p><ul><li>Internal and External Storage</li><li>Serialisation</li><li>Exporting and importing datasets</li></ul></li><li><p>GUI functionality</p><ul><li>Buttons</li><li>Visualising</li></ul></li></ul></li><li><p><strong>Results</strong></p><ul><li>Initial results</li><li>Using sophisticated feature extraction</li><li>Mean approximation</li><li>Kmeans clustering</li><li>Cryptographic substitution frequency analysis</li></ul></li></ol><hr /><h2><a name='header-n1158' class='md-header-anchor '></a>1. Introduction</h2><h3><a name='header-n1161' class='md-header-anchor '></a>1.1 Author &amp; Date</h3><p>This project was started in January of 2017 and finished in August of 2017, with the current dated version of this corpus being 21/8/2017.</p><p>The author of this corpus is Daniel Jack Andrews, if you have any queries you can contact the author at <a href='mailto:dja33@kent.ac.uk'>dja33@kent.ac.uk</a>.</p><h3><a name='header-n1227' class='md-header-anchor '></a>1.2 Abstract &amp; Aim</h3><h4><a name='header-n1230' class='md-header-anchor '></a>1.2.1 Abstract</h4><p>Nearly every user on the market owns a smartphone within the western first world. These modern day smartphones often contain technology that is more powerful and sophisticated that the rockets that delivered man to the moon.</p><p>Considering this the potential power behind the average smartphone is huge, even for the purpose of breaking security measures. Computer keyboards are not a new invention and have been rooted to the development of computers since their creation; however they are fundamentally at the hand of every and all sensitive data entry. Sensitive data could reflect bank details, passwords, personal or confidential information and more. </p><p>The dissertation that this corpus supports aims to challenge whether a modern day smartphone can acoustically eavesdrop on a keyboard through side-channels in the acoustic noise produced by pressing the keys on the board.</p><h4><a name='header-n1273' class='md-header-anchor '></a>1.2.2 Aim</h4><p>This corpus aims to provide and support the dissertation associated with it such that any reference of relation to the material, results or development of the dissertations logic, applicants or findings can be backed up and catalogued. This corpus will skim over certain aspects of the project, where instead these details can be found in the bulk of the dissertation. Instead this corpus aims to provide a uniformed catalogue of data used as referencing points in the dissertation thesis itself.</p><h3><a name='header-n1284' class='md-header-anchor '></a>1.3 Special Thanks</h3><p>This project could not have been completed without the following people and groups who have provided wonderful guidance and support throughout the project.</p><ul><li><p>Budi Arief - Supervisor, computer security lecturer.</p><ul><li>Met with me regularly to conduct guidance meetings and help keep me on track of the topic at hand, always firm and willing to provide assistance when needed.</li><li>Founded the project concept and passed it onto me.</li></ul></li><li><p>Samuel Williams - PhD candidate, programming language implementation specialist.</p><ul><li>Provided fantastic knowledge on artificial intelligence and had a deep appreciation for the research topic covered in this material.</li></ul></li><li><p>Alice Mo - Data Mining Analyst and MSc candidate at University College London</p><ul><li>Fundamentally showed and helped deal with resolving data and identifying useful traits in it.</li></ul></li><li><p>Michael Berry - PhD, software engineer, electronics tinkerer and radio licence holder.</p><ul><li>Provided assistance on digital signal processing, explaining Fourier transforms and utilising feature extraction.</li></ul></li><li><p>The Shed - Group of knowledgeable technicians with a wealth background experience in varying fields.</p><ul><li>Helped laser cutting a frame and suggesting potential fixes to issues.</li></ul></li></ul><hr /><h2><a name='header-n1438' class='md-header-anchor '></a>2. Meetings</h2><h3><a name='header-n1423' class='md-header-anchor '></a>2.1 Purpose</h3><p>On several occasions I met my supervisor Budi Arief to discuss the project undertaken. These meetings were intended to provide insight into the current status of the project while assisting in any issues and providing other forms of support to the project.</p><h3><a name='header-n1475' class='md-header-anchor '></a>2.2 Audio recordings</h3><p>Unfortunately I have only three audio recorded sessions as my audio recording equipment failed on two occasions. Below are the three recorded meetings I do have access to. For all other meetings I took detailed notes on our discussions.</p><ul><li>15/5/2017 (In person) - <a href='meetings_audio/15.05.m4a'>View</a></li><li>21/7/2017 (In person) - <a href='meetings_audio/21.07.m4a'>View</a></li><li>14/8/2017 (On Skype) - <a href='https://youtu.be/ac2mPSi0TXU'>View</a></li></ul><p>In-between June and August I lost two of my recordings. </p><h3><a name='header-n1504' class='md-header-anchor '></a>2.3 Meeting summaries</h3><h5><a name='header-n1594' class='md-header-anchor '></a>31/1/2017 - Initial Preparation</h5><p>Discussed hardware capabilities, such as whether the phone being used has multiple microphones, where they are and what sort of sensors to utilise.</p><p>Discussed controlled environment settings:</p><ul><li>Specific keyboard to use, in this case mechanical keyboard model &quot;Razer BlackWidow 2014 Ultimate&quot; - using Razers patterned mechanical keys.</li><li>Specific to Android OS only for the purpose of the research</li><li>20 presses of specific keys, &#39;Q&#39;, &#39;W&#39;, etc.</li><li>Lasercut potential frame to hold keyboard and phone, ensure that the distance between them is always fixed and therefore stops variations in this.</li><li>Decided to use my Android phone to do this project under.</li><li>Keys such as space will be hard to identify due to their size and potential to be struck in varying places.</li></ul><p>Other items to note:</p><ul><li>Research into Side-Channel attacks, use Google scholar or the similar academic search engine.</li><li>Pattern databases.</li><li>Look into Accelerometer feature set and how it interacts with the Android OS.</li><li>Record the results of whatever happens.</li></ul><h5><a name='header-n1653' class='md-header-anchor '></a>17/2/2017 - Measuring Raw Data</h5><ul><li><p>Produced a small demo Application for Android that will report sensory data from the phone, discussed which keys to focus on and just recording the values for the time being before trying to identify any particular pattern.</p></li><li><p>Use keys that are of varying sizes and distances away from one another to help for identification, keys mention included:</p><ul><li>Q</li><li>ENTER</li><li>SLASH</li><li>W</li><li>H</li><li>SPACE</li></ul></li><li><p>Investigate potentially new technologies</p></li><li><p>Research into feature extraction to further develop an understanding of the topic material</p><ul><li><p>For sound:</p><ul><li>Amplitude</li><li>Frequency (Fast Fourier Transform, algorithm adapted from discrete fourier transform)</li></ul></li><li><p>For accelerometer:</p><ul><li>X, Y, Z forces</li><li>Speed</li><li>Also capable of performing FFT on these as well</li></ul></li><li><p>Alternatively, potential for Gyroscopic sensor too.</p></li></ul></li></ul><h5><a name='header-n1714' class='md-header-anchor '></a>28/2/2017 - Initial Attempt at Isolating Raw Data</h5><p>Initially this was a demoralising iteration, I found that the accelerometer was slow within the Android SDK and that I would not reliable be able to identify or determine key presses given such little ranging values over a sample, such that I decided for the time being to focus solely on acoustic keylogging rather other features. </p><p>Decided to go back to the &#39;drawing&#39; board and look at research more thoroughly, other assessments had gotten in my way and little work had been made through this iteration.</p><p>Had difficulties isolating the memory storage on the Smartphone as it appeared under a &#39;virtual&#39; filesystem such that I couldn&#39;t accurately locate the file that I was saving all my samples and readings to.</p><p>Found that amplitude wasn&#39;t a good measurement for feature extraction alone and that frequency would be an absolute requirement.</p><p>Had laser cut a frame however to hold the phone and keyboard in place.</p><h5><a name='header-n1792' class='md-header-anchor '></a>March, April, May</h5><p>A lot of this time was spent working on assessments, exams and job interviews. Evaluation of research was the focus in this period while the development occurred post June. As such I shall present the researched papers and a link to my evaluations of those. These papers provided the foundation of the majority of my work, with research from Andrew Kelly featuring prominently.</p><ul><li>Cracking Passwords using keyboard Acoustics and Language Modeling - Andrew Kelly (2010)</li><li>Keyboard Acoustic Emanations - Asonov and Agrawal (2004)</li><li>Keyboard Acoustic Emanations Revisited - Zhang, Feng, Tygar (2009)</li></ul><h5><a name='header-n1890' class='md-header-anchor '></a>15/06/2017 - Pre deliverable submission</h5><p><a href='meetings_audio/15.05.m4a'>Audio</a></p><p>We discussed what had been completed so far for the project, I had scrapped my previous codebase as I wasn&#39;t happy with the quality of it. As such the focus at this part was that the research had been fully conducted in the project. </p><p>We focused on three main elements of the project after research:</p><ul><li><p>Experimentation and methodology</p><ul><li>Consistent testing</li><li>A lab condition</li><li>Training data sets on keypresses</li></ul></li><li><p>Implementing a proof of concept</p><ul><li>On the Android operating system</li><li>Focussing on live-recorded audio</li><li>Some form of machine learning involved</li></ul></li><li><p>Other ideas for later use</p><ul><li>Dictionary based attack to decipher potentially misspelled English words</li><li>Potential to then get the context behind a message, the emotion and power play of the words</li><li>Biometric profile of the individual</li></ul></li></ul><h5><a name='header-n2030' class='md-header-anchor '></a>6/07/2017 - Implementation progress update</h5><p>Unfortunately I lost the recording for this meeting but I did however make some notes on the topics mentioned. The focus of the meeting was applying a Fourier transform across a discrete dataset of values for analysis in the frequency domain. Such that we could later pass this into a feature extraction function that would return us distinct features of keystrokes.</p><h5><a name='header-n2094' class='md-header-anchor '></a>12/07/2017 - Implementation progress update</h5><p>Another lost audio recording for this meeting.</p><p>I had successfully written a feature extraction algorithm that was able to identify distinct differences in frequency and magnitude between two key presses, albeit there were complications with live audio recording as to be expected.</p><p>The next focus on was on refining this feature extraction if possible and looking into a primitive machine learning algorithm to help classify and train the keys being pressed. In this case the focus being on a supervised algorithm.</p><h5><a name='header-n2078' class='md-header-anchor '></a>21/7/2017</h5><p><a href='meetings_audio/21.07.m4a'>Audio</a></p><p>A setback  occurred where my AudioRecord API ceased to operate and instead started spurring errors, after fixing these owing to updated Android API permission system the project was back on track.</p><p>Discussed the possibility of focussing on multiple keyboards but for the time being decided to look at just one keyboard until later period. Talked about storing the data and dealing with Androids file system in a manner that can be adjusted accordingly if need be. Java offers serialisation, a useful mechanism of preserving the data encapsulated within an object at runtime; potential for this tool to be used. Preserving data comes in the form of being able to then use this as a measurement of comparison for later, i.e I&#39;m able to identify the key C because I have told my program from training that key C sounds like this.</p><p>Decided that the phone should handle everything, previously there was a thought of potentially having a machine elsewhere decode the live audio into information but instead the confirmation of the phone being the sole processing machine was decided. Rationality for this was user ability, if anyone owns a phone then they also can do what this project aims for.</p><p>Discussed potentially having a visual display of characters being decoded as an end goal, however for this to be effective it would require that the device was able to quickly identify as many keys as possible as well as having a high degree of accuracy in doing so.</p><p>Talked briefly about Mel-cepstrum Frequency Analysis, a technique often used in voice recognition systems although this methodology was too foreign to be adopted. </p><p>Finished up with discussing the corpus and dissertation display and layout, decided to use markdown and provide the corpus in a HTML relative structure.</p><h5><a name='header-n2153' class='md-header-anchor '></a>14/8/2017 (On Skype)</h5><p><a href='https://youtu.be/ac2mPSi0TXU'>Audio</a> - Provided on YouTube, otherwise it&#39;s 1.4GB.</p><p><strong>Note</strong> - The previous 3 weeks consisted of back and forth between me and Budi, trying to arrange a meeting as both of us were unavailable at several periods. </p><p>This meeting was a final conclusive meeting of the project coming to an end. I spent time explaining the working system for the keylogger as well as providing details on several anecdotes regarding the system. Details included:</p><ul><li>Feature extraction</li><li>Mean average supervised learning</li><li>Kmeans unsupervised learning</li><li>Saving results</li><li>Identifying keystrokes based on results</li></ul><p>The he results of kmeans clustering were more accurate than mean average, kmeans scored around ~60% while mean average scored around ~52%. At this point the focus was on writing the corpus and working towards the dissertation. </p><p><strong>Note</strong> - A final meeting is planned for the 29/8/2017 but since the Corpus will have been submitted it will not be documented, this meeting aims to provide details and feedback on the state of the dissertation.</p><hr /><h2><a name='header-n2281' class='md-header-anchor '></a>3. Research</h2><h3><a name='header-n2286' class='md-header-anchor '></a>3.1 Accelerometer Side Channel Attacks</h3><p><a href='research/AccelerometerSideChannel.pdf'>Paper</a></p><p>Using the accelerometer on Android based smartphones to determine a users phone pin/pattern unlocking code. Research in this field shows that success rates in controlled environments are high (such as the user sitting down being motionless) whereas in uncontrolled environments rates dropped but still maintained a concerning high level of accuracy.</p><p>They provided relevant research from others in the field in similar veins of collecting data, previous papers referenced in this include:</p><ul><li><a href='research/TouchLogger.pdf'>TouchLogger</a>: Inferring Keystrokes On Touch Screen From Smartphone Motion</li><li><a href='research/TapPrints.pdf'>TapPrints</a>: Your Finger Taps Have Fingerprints - focuses on a similar vein of research as the source but utilises gyroscopic and accelerometer data to infer key presses.</li></ul><p>The paper makes reference to different MAXIMUM sample rates of certain phones and through my own research I&#39;ve found a piece of <a href='https://github.com/dantasse/AccelerometerTest/'>software</a> capable of measuring the speed of a phones accelerometer which will be useful later in my own research.</p><p>They used multiple phones to correlate their findings with varying refresh rates. Collected 5 samples of each pin/pattern entry but before this had each tester enter 50 random pins/patterns with their dominant hand then following this doing the same but walking around.</p><ul><li><p>The controlled data (Sitting) was used for training.</p></li><li><p>The variable data (Walking) was used for testing.</p></li><li><p>Utilising multiple mathematical formula to try to classify the data in a meaningful manner.</p><ul><li>Mean Normalisation, Linear Normalisation, Quadratic Normalisation</li><li>iFFT-Poly, iFFT-Acc and 3D-Polynominal graphing</li></ul></li></ul><p>Utilising these formula they found a large <strong>variance</strong> between values, even when entering the same pin and such that they needed to <strong>normalise</strong> the raw signal. They used a 1-dimensional Discrete Fourier Transform with a resolution of 35 samples and found that the larger sample set would add to much variance while a smaller sample set would not preserve enough information.</p><p>The paper talks in detail about using Hidden Markov Models to predict unknown pins due to the limitations of having a classifier that only knows the patterns given by users.</p><p>They then suggest potential solutions to the problem presented:</p><ul><li>Vet programs that use sensors, try to identify any malicious behaviour or intent. Scale is too hard for this.</li><li>Restrict sampling rate, but as the paper demonstrates even at 20KHz still possible to monitor fairly accurately.</li><li>Utilise a permission model warning users about the permissions given to an app, mostly ignored by the user anyway.</li></ul><p>Their suggested solution is:</p><ul><li>Disable the sensors whenever a trust related action is being performed, such as entering a password. Current security models do not allow for this, but future proofing may be required.</li></ul><p><strong>Conclusion</strong></p><p>Conclusively the paper ends by explaining that a side-channel attack is possible and potentially dangerous even with noise introduced, drawing parallels between itself and other papers in the field it makes use to explain how one could expand upon the research. </p><p>However this research focuses on inferring data from then touchscreen and does not guarantee that the same can be used for keystrokes on a physical keyboard. (As it later turns out, this is the true that Android is too limited to be able to deduce another features alone from vibrations for keystroke analysis)</p><h3><a name='header-n2755' class='md-header-anchor '></a>3.2 Keyboard Acoustic Emanations</h3><p><a href='research/KeyboardAcousticEmanations.pdf'>Paper</a></p><p>Written in 2004 the original paper addresses the ability to identify with a high degree of accuracy keystrokes from emanations created from sound via side-channel attacks. Asonov and Agrawal provide a detailed understanding of the attack, how it works, why it works and methods to potentially disable or weaken the attack.</p><p>The paper expands by explaining that they recorded 2-3ms worth of the ’touch-peak’ in which they are able to extract reliable features from the sample given. That initially they tested keys ’l’ and ’k’ individually 100
times and then fed the results as a key-value pair into an neural network. The neural network was then able to identify each key press of ’l’ and ’k’ with a given 100% accuracy, however this initial experiment was at a
performance of 1 metre with a microphone that may potentially exceed the capabilities of the Samsung S4s microphone. Later they experimented with variable distances and background noise with just keys ’l’ and ’k’ to challenge the accuracy of the neural network; with a distance of up to 15 metres. They reported no changes in their results given this knowledge.</p><p>Later they extended their keyset to 30 keys and noted the accuracy of given keys to the network, even expanding into the realm of utilising a separate keyboard. They found a given accuracy of 79% out of 300 ’test’ clicks.</p><p>They acknowledge that in the tests provided so far, the same user provided input onto the keys, such that they had trained a network in the users biometric attitude towards the keyboard. They found that given
a change in person and approach to impact pressure applied to each key that their neural network resulted in poor behaviour.</p><p>Their work expands into other touch-based input systems such as telephones, ATMs and more - however this escapes beyond the realm of our research. Finally they suggest a mechanism to counter this attack vector, using silent keyboards such as non-mechanical however they note the price and lack of
comfort these provide to users.</p><p><strong>Conclusion</strong></p><p>The most detailed aspect of this research is the &#39;touch-peak&#39; of 2-3ms and training data, they utilise important methods that can be followed up on for my work. I plan to follow a similar pattern of testing two individual keys, then 5, then a range of keys. </p><h3><a name='header-n2655' class='md-header-anchor '></a>3.3 Keyboard Acoustic Emanations Revisited</h3><p><a href='research/KeyboardAcousticEmanationsRevisited.pdf'>Paper</a></p><p>In 2009 Zhang, Feng and Tygar of the University of California produced a paper that expanded upon Asonov and Agrawals in the hope to address the inefficiency of their neural network. In their paper they report a success of identifying up to 96% accuracy when disregarding a new for training label data within a 10 minute period of sound recording. They announce the success of a 90% accuracy within 5 character random password identification with only the use of letters in fewer than 20 attempts by the adversary, leading to %80 accuracy within 75 attempts at 10 character random passwords.</p><p>They incorporate the use of the constraints applied by the English language and as such utilise a dictionary to help identify potentially invalid words and replace them with the most likely correct alternative.</p><p>They quickly address the previous flaws laid out by Asonov and Agrawals paper in which labelled training data is required for learning and given the same environmental variables are in play, variables in key impact
pressure lead to a severe failure within the previous paper.</p><p>The paper regards a superior technique over FFT for feature extraction and training of the neural network by utilising cepstrum features which details higher than FFT. Interestingly they admit that they are not aware whether the victim may be writing in English but instead address this by saying that given the accuracy of their results it would become apparent whether the user was writing in English or not given a few attacks.</p><p>They use clustering to help apply a class to each keystroke to a key but admit that it is potentially unreliable and as such much seed it randomly to avoid obvious overlap. A HMM (Hidden Markov Model) is used to correctly identify typical positioning of characters and likelihood of positioning given the English language, an example being ’h’ coming after ’t’ to form ’th’. Afterwards utilising a speller and grammar checking system to fill in any potentially unknown variables within words. Finally they apply this to a feedback trainer
which helps the classifier to identify potential random text at a later for password recognition. They only utilise words that had less than 1/4 of their components correct to help train the classifier and with this are able to identify the quality of the classifier; more feedback equals better quality as less mistakes have been made in the classification program.</p><p><strong>Conclusion</strong></p><p>The big push in this research is the use of Mel-cepstrum over FFT, although this technique is superior at analysis it is far more complex and could potentially be beyond my capabilities but is worth noting in detail. FFT is an easy technique to implement while Mel-cepstrum has been notably used in voice recognition software. They utilise clustering (see later on kmeans clustering) to classify keystrokes but describe this technique as &#39;standard clustering methods&#39; (later research explains more detail kmeans clustering).</p><h3><a name='header-n2881' class='md-header-anchor '></a>3.4 Cracking Passwords using keyboard acoustics and language modelling</h3><p><a href='research/crackingpasswords.pdf'>Paper</a></p><p>One very substantial prior research piece is that of Andrew Kellys similar exploration into acoustic keylogging by building of the previous research of Asonov and Agrawal in 2004. The piece written in 2010 demonstrates extensive understanding of techniques provided by Asonov and Agrawal while expanding upon them to deliver a clear depth of expansive knowledge. Kelly provides an overview of different stages utilised in the
project with each stage isolating requirements for the project as a hole. Kelly explains the use of a ’press-peak’ for analysing the acoustic features from a keystroke which is compromised of two separate components a touch-peak and hit-peak; the touch-peak providing a further detailed analysis for digital
sound signalling.</p><p><img src='research/images/kae.png' alt='kae' /></p><p>Kelly explains the use of Asonovs and Agrawals neural networks for classifying keystrokes which resulted in a 79% success rate, this attack vector required labelled training data and suffered from variations in
accuracy with the pressure applied to each keystroke. Later Kelly mentions the expansion of this attack vector provided by Zhang, Zhou and Tygar in 2009, in which they utilised an unsupervised clusters of keystrokes - feeding these into unigram and bigram statistics to map clusters to the correct keys and later
applying a language model and dictionary for spell checking to then feed into a supervised classifier with the correct text. Kelly notes that Zhang, Zhou and Tygar found that utilising cepstrum feature extraction
over FFT (Fast Fourier Transform) yielded a much higher accuracy. By using a spell checker with a dictionary they were able to train their classifier and provide more accurate results when analysing keystrokes.</p><p>The paper explains that keystrokes often fall within the frequency range of 400-12000Hz, although Kelly does not explain whether the keyboards used are membrame or mechanical, in the case of our project - it’s a mechanical keyboard.</p><p><strong>Conclusion</strong></p><p>Overall I have provided a small subset of Kellys early analysis in his paper but the important details like in his use of feature extraction via FFT and Mel-cepstrum frequency analysis. The use of kmeans clustering over supervised learning is an interesting concept but I hope to implement both to verify these findings myself as machine learning is not a concept I am personally too familiar with.</p><h2><a name='header-n2930' class='md-header-anchor '></a>4. Hardware</h2><p>...</p></div>
</body>
</html>